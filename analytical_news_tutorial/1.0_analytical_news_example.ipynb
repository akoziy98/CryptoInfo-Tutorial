{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "X_RAPIDAPI_KEY = os.environ.get(\"X_RAPIDAPI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze news between time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cryptoinfo.p.rapidapi.com/api/private/news_between_time_analyze\"\n",
    "\n",
    "payload = {\n",
    "\t\"time_start\": \"2023-01-20 17:34:58+00:00\",\n",
    "\t\"time_finish\": \"2023-01-23 17:34:58+00:00\",\n",
    "\t\"fields_to_search\": [\"crypto\"],\n",
    "\t\"tickers_to_search\": [\"BTC\"],\n",
    "\t\"hashtags_to_search\": [\"#Crypto\"],\n",
    "\t\"is_unique\": 1,\n",
    "\t\"is_appropriate\": 1,\n",
    "\t\"discretize_period\": 1\n",
    "}\n",
    "headers = {\n",
    "\t\"content-type\": \"application/json\",\n",
    "\t\"Accept\": \"application/json\",\n",
    "\t\"X-RapidAPI-Key\": X_RAPIDAPI_KEY,\n",
    "\t\"X-RapidAPI-Host\": \"cryptoinfo.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "print(response.status_code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "res_analyt = json.loads(response.text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request overview\n",
      "time start and time finish is boundary time of news to get analysis. It should be in format: %Y-%m-%d %H:%M:%S%z\n",
      "fields_to_search (['crypto']) -- first level keys in fields_tickers field in news data. fields_to_search can be: crypto, resources, fx, american, russian, token_sale. You can add some of them as a list, or comment this string, by default all news will be used. It searches for news, that include fields_to_search in fields_tickers\n",
      "tickers_to_search (['BTC']) -- values for keys in fields_tickers field in news data. tickers_to_search can be chosen from file: tickers_to_search.xlsx in this directory. You can add some of them as a list or comment this string, by default all news will be used. It searches for news, that includes tickers_to_search in fields_tickers values\n",
      "hashtags_to_search (['#Crypto']) -- find news by hashtags in hashtags_list news field. hashtags_to_search can be chosen from file: hashtags_to_search.xlsx in this directory (And you need to convert your search string for \\# + first symbol uppercase). You can add some of them as a list or comment this string, by default all news will be used.\n",
      "is_unique (1) -- find only unique news (1); find only ununique news (-1); find both (0)\n",
      "is_appropriate (1) -- search for news that can be published according to our block-words settings (1); search for news that can't be published (-1); search for both (0)\n",
      "discretize_period (1) -- discretization step of time period from time_start to time_finish, in hours. It can be only int >= 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Request overview\")\n",
    "print(\"time start and time finish is boundary time of news to get analysis. It should be in format: %Y-%m-%d %H:%M:%S%z\")\n",
    "print(f\"fields_to_search ({payload['fields_to_search']}) -- first level keys in fields_tickers field in news data. fields_to_search can be: crypto, resources, fx, american, russian, token_sale. You can add some of them as a list, or comment this string, by default all news will be used. It searches for news, that include fields_to_search in fields_tickers\")\n",
    "print(f\"tickers_to_search ({payload['tickers_to_search']}) -- values for keys in fields_tickers field in news data. tickers_to_search can be chosen from file: tickers_to_search.xlsx in this directory. You can add some of them as a list or comment this string, by default all news will be used. It searches for news, that includes tickers_to_search in fields_tickers values\")\n",
    "print(f\"hashtags_to_search ({payload['hashtags_to_search']}) -- find news by hashtags in hashtags_list news field. hashtags_to_search can be chosen from file: hashtags_to_search.xlsx in this directory (And you need to convert your search string for \\# + first symbol uppercase). You can add some of them as a list or comment this string, by default all news will be used.\")\n",
    "print(f\"is_unique ({payload['is_unique']}) -- find only unique news (1); find only ununique news (-1); find both (0)\")\n",
    "print(f\"is_appropriate ({payload['is_appropriate']}) -- search for news that can be published according to our block-words settings (1); search for news that can't be published (-1); search for both (0)\")\n",
    "print(f\"discretize_period ({payload['discretize_period']}) -- discretization step of time period from time_start to time_finish, in hours. It can be only int >= 1\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response overview\n",
      "Result of this analytical endpoint consists of two fields: dict_keys(['aggregated', 'discretized'])\n",
      "aggregated -- all news statistics calculated for the whole time range\n",
      "discretized -- news statistics calculated in time windows with size discretize_period\n",
      "==============\n",
      "Let's overview data on aggregated field: dict_keys(['fields', 'tickers', 'hashtags_list', 'sentiment', 'article_label', 'article_type', 'url', 'number_of_articles'])\n",
      "All data sorted from most popular to least\n",
      "fields -- shows statistics on fields: {'crypto': {'count': 138, 'positive': 93, 'neutral': 24, 'negative': 21}, 'american': {'count': 15, 'positive': 10, 'neutral': 2, 'negative': 3}, 'token_sale': {'count': 11, 'positive': 7, 'neutral': 1, 'negative': 3}, 'resources': {'count': 8, 'positive': 4, 'neutral': 3, 'negative': 1}, 'russian': {'count': 7, 'positive': 4, 'neutral': 2, 'negative': 1}, 'fx': {'count': 0, 'positive': 0, 'neutral': 0, 'negative': 0}}\n",
      "Each element for the key field, has the next fields: count -- total number of news; positive, neutral, negative -- number of news with such sentiment\n",
      "tickers -- shows statistics on tickers, that corresponds to specific fields. We present only part of possible tickers from crypto (without sentiment statistics): ['BTC', 'ETH', 'BNB', 'XRP', 'DOGE', 'SOL', 'ADA', 'SHIB', 'TRX', 'APT']\n",
      "hashtags_list -- show statistics on hashtags. We will present only part of hashtags without sentiment statistics: ['#Crypto', '#BTC', '#Price', '#Week', '#Market', '#Year', '#Million', '#Cryptocurrency', '#ETH', '#Month']\n",
      "sentiment -- total sentiment statistics: {'positive': 93, 'neutral': 24, 'negative': 21}\n",
      "article_label -- shows statistics for different article labels: {'statistics': {'count': 62, 'positive': 51, 'neutral': 7, 'negative': 4}, 'news': {'count': 49, 'positive': 25, 'neutral': 10, 'negative': 14}, 'overview': {'count': 19, 'positive': 13, 'neutral': 5, 'negative': 1}, 'undefined': {'count': 8, 'positive': 4, 'neutral': 2, 'negative': 2}}\n",
      "article_type -- shows statistics for different article types: {'business': {'count': 101, 'positive': 68, 'neutral': 21, 'negative': 12}, 'sci_tech': {'count': 34, 'positive': 24, 'neutral': 2, 'negative': 8}, 'world': {'count': 3, 'positive': 1, 'neutral': 1, 'negative': 1}, 'sports': {'count': 0, 'positive': 0, 'neutral': 0, 'negative': 0}}\n",
      "url -- shows all list of news urls: ['https://u.today/heres-where-crypto-stolen-by-north-korea-from-lazarus-group-actually-went', 'https://u.today/bitcoin-btc-shows-impressive-growth-in-january-alone-beating-ethereum-eth-details', 'https://www.coindesk.com/policy/2023/01/23/european-banks-must-fully-cover-crypto-holdings-with-capital-draft-text-says/?utm_medium=referral&utm_source=rss&utm_campaign=headlines', 'https://www.coindesk.com/consensus-magazine/2023/01/23/the-worlds-best-crypto-policies-how-they-do-it-in-37-nations/?utm_medium=referral&utm_source=rss&utm_campaign=headlines', 'https://news.bitcoin.com/economist-mohamed-el-erian-predicts-sticky-inflation-despite-federal-reserves-efforts-to-bring-it-down/']\n",
      "number_of_articles -- shows total number of articles: 138\n",
      "==============\n",
      "Let's overview discretized data\n",
      "It consists of dict with different keys, that represents time ranges. Each element has the same structure as aggregated field. But also there are two keys that responsible for start and finish of time period: range_start and range_finish\n",
      "First time range has key 0. range start: 2023-01-20 17:00:00+00:00 and range finish: 2023-01-20 18:00:00+00:00\n",
      "last time range has key 72 in this example. range start: 2023-01-23 17:00:00+00:00 and range finish: 2023-01-23 18:00:00+00:00\n",
      "Important point. We round up the range_start and range_finish for the first and the last periods. If you make a retieval, as in this example, not in 17:00:00, your data will start from 17:34:58, but time range will be set to 17:00. Likewise for time_finish of retrieval, there is upper rounding. This is suitable for graphics plotting\n"
     ]
    }
   ],
   "source": [
    "print(\"Response overview\")\n",
    "print(\"Result of this analytical endpoint consists of two fields:\", res_analyt.keys())\n",
    "print(\"aggregated -- all news statistics calculated for the whole time range\")\n",
    "print(\"discretized -- news statistics calculated in time windows with size discretize_period\")\n",
    "print(\"==============\")\n",
    "print(\"Let's overview data on aggregated field:\", res_analyt[\"aggregated\"].keys())\n",
    "print(\"All data sorted from most popular to least\")\n",
    "print(\"fields -- shows statistics on fields:\", res_analyt[\"aggregated\"][\"fields\"])\n",
    "print(\"Each element for the key field, has the next fields: count -- total number of news; positive, neutral, negative -- number of news with such sentiment\")\n",
    "print(\"tickers -- shows statistics on tickers, that corresponds to specific fields. We present only part of possible tickers from crypto (without sentiment statistics):\", list(res_analyt[\"aggregated\"][\"tickers\"][\"crypto\"].keys())[:10])\n",
    "print(\"hashtags_list -- show statistics on hashtags. We will present only part of hashtags without sentiment statistics:\", list(res_analyt[\"aggregated\"][\"hashtags_list\"].keys())[:10] )\n",
    "print(\"sentiment -- total sentiment statistics:\", res_analyt[\"aggregated\"][\"sentiment\"])\n",
    "print(\"article_label -- shows statistics for different article labels:\", res_analyt[\"aggregated\"][\"article_label\"])\n",
    "print(\"article_type -- shows statistics for different article types:\", res_analyt[\"aggregated\"][\"article_type\"])\n",
    "print(\"url -- shows all list of news urls:\", res_analyt[\"aggregated\"][\"url\"][:5])\n",
    "print(\"number_of_articles -- shows total number of articles:\", res_analyt[\"aggregated\"][\"number_of_articles\"])\n",
    "print(\"==============\")\n",
    "print(\"Let's overview discretized data\")\n",
    "print(\"It consists of dict with different keys, that represents time ranges. Each element has the same structure as aggregated field. But also there are two keys that responsible for start and finish of time period: range_start and range_finish\")\n",
    "print(f\"First time range has key 0. range start: {res_analyt['discretized']['0']['range_start']} and range finish: {res_analyt['discretized']['0']['range_finish']}\")\n",
    "print(f\"last time range has key 72 in this example. range start: {res_analyt['discretized']['72']['range_start']} and range finish: {res_analyt['discretized']['72']['range_finish']}\")\n",
    "print(\"Important point. We round up the range_start and range_finish for the first and the last periods. If you make a retieval, as in this example, not in 17:00:00, your data will start from 17:34:58, but time range will be set to 17:00. Likewise for time_finish of retrieval, there is upper rounding. This is suitable for graphics plotting\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you don't want to use fields_to_search, tickers_to_search, hashtags_to_search filters, you can simply comment it out in your request\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cryptoinfo.p.rapidapi.com/api/private/news_between_time_analyze\"\n",
    "\n",
    "print(\"if you don't want to use fields_to_search, tickers_to_search, hashtags_to_search filters, you can simply comment it out in your request\")\n",
    "\n",
    "payload = {\n",
    "\t\"time_start\": \"2023-01-20 17:34:58+00:00\",\n",
    "\t\"time_finish\": \"2023-01-23 17:34:58+00:00\",\n",
    "\t#\"fields_to_search\": [\"crypto\"],\n",
    "\t#\"tickers_to_search\": [\"BTC\"],\n",
    "\t#\"hashtags_to_search\": [\"#Crypto\"],\n",
    "\t\"is_unique\": 1,\n",
    "\t\"is_appropriate\": 1,\n",
    "\t\"discretize_period\": 1\n",
    "}\n",
    "headers = {\n",
    "\t\"content-type\": \"application/json\",\n",
    "\t\"Accept\": \"application/json\",\n",
    "\t\"X-RapidAPI-Key\": X_RAPIDAPI_KEY,\n",
    "\t\"X-RapidAPI-Host\": \"cryptoinfo.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "print(response.status_code)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
